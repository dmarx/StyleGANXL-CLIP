{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmarx/StyleGANXL-CLIP/blob/main/StyleganXL%2BCLIP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K74zxktiQyub"
      },
      "source": [
        "# **StyleGANXL + CLIP ðŸ–¼ï¸**: SlightlyStable edition via DigThatData\n",
        "\n",
        "## Generate images from text prompts using StyleGANXL with CLIP guidance.\n",
        "\n",
        "(Modified by Katherine Crowson to optimize in W+ space)\n",
        "\n",
        "This notebook is a work in progress, head over [here](https://github.com/CasualGANPapers/unconditional-StyleGAN-CLIP) if you want to be up to date with its changes.\n",
        "\n",
        "Largely based on code by  [Katherine Crowson](https://github.com/crowsonkb) and [nshepperd](https://github.com/nshepperd).\n",
        "\n",
        "Mostly made possible because of [StyleGAN-XL](https://github.com/autonomousvision/stylegan_xl) and [CLIP](https://github.com/openai/CLIP).\n",
        "\n",
        "Created by [Eugenio Herrera](https://github.com/ouhenio) and [Rodrigo Mello](https://github.com/ryudrigo).\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #**Install stuff** ðŸ—ï¸ðŸ› ï¸\n",
        "# @markdown This cell will take a while.\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#!git clone https://github.com/autonomousvision/stylegan_xl\n",
        "!pip install einops ninja\n",
        "!pip install timm\n",
        "!pip install napm \n",
        "\n",
        "#sys.path.append('./stylegan_xl')\n",
        "import napm\n",
        "url = 'https://github.com/autonomousvision/stylegan_xl'\n",
        "napm.pseudoinstall_git_repo(url, add_install_dir_to_path=True)"
      ],
      "metadata": {
        "id": "q1rorXlU86h6",
        "outputId": "98fb6103-060d-44df-bc59-3b8aac12d633",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.7/dist-packages (0.4.1)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.7/dist-packages (1.10.2.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.7/dist-packages (0.6.7)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.12.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.13.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (2.28.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2022.6.15)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (1.24.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: napm in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: gdown<5.0.0,>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from napm) (4.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.27.1 in /usr/local/lib/python3.7/dist-packages (from napm) (2.28.1)\n",
            "Requirement already satisfied: loguru<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from napm) (0.6.0)\n",
            "Requirement already satisfied: omegaconf<3.0.0,>=2.1.1 in /usr/local/lib/python3.7/dist-packages (from napm) (2.2.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown<5.0.0,>=4.4.0->napm) (4.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown<5.0.0,>=4.4.0->napm) (3.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown<5.0.0,>=4.4.0->napm) (4.64.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown<5.0.0,>=4.4.0->napm) (1.15.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.7/dist-packages (from omegaconf<3.0.0,>=2.1.1->napm) (4.9.3)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from omegaconf<3.0.0,>=2.1.1->napm) (6.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.27.1->napm) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.27.1->napm) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.27.1->napm) (2022.6.15)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.27.1->napm) (2.1.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.27.1->napm) (1.7.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-07-27 23:28:37.626 | DEBUG    | napm.pseudo_install:pseudoinstall_git_repo:64 - Added /root/.cache/napm/stylegan_xl to sys.path\n",
            "2022-07-27 23:28:37.628 | DEBUG    | napm.config:config_path:28 - /root/.cache/napm/config.yaml\n",
            "2022-07-27 23:28:37.637 | DEBUG    | napm.config:config_path:28 - /root/.cache/napm/config.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import mmc\n",
        "except:\n",
        "    # install mmc\n",
        "    !git clone https://github.com/dmarx/Multi-Modal-Comparators\n",
        "    !pip install poetry\n",
        "    !cd Multi-Modal-Comparators; poetry build\n",
        "    !cd Multi-Modal-Comparators; pip install dist/mmc*.whl\n",
        "    !python Multi-Modal-Comparators/src/mmc/napm_installs/__init__.py\n"
      ],
      "metadata": {
        "id": "0Xvpuh_j9jW9",
        "outputId": "a4de148d-7339-412f-9340-7824afd8e313",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Multi-Modal-Comparators'...\n",
            "remote: Enumerating objects: 669, done.\u001b[K\n",
            "remote: Counting objects: 100% (118/118), done.\u001b[K\n",
            "remote: Compressing objects: 100% (71/71), done.\u001b[K\n",
            "remote: Total 669 (delta 50), reused 74 (delta 38), pack-reused 551\u001b[K\n",
            "Receiving objects: 100% (669/669), 819.22 KiB | 10.37 MiB/s, done.\n",
            "Resolving deltas: 100% (387/387), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting poetry\n",
            "  Downloading poetry-1.1.14-py2.py3-none-any.whl (175 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 175 kB 15.0 MB/s \n",
            "\u001b[?25hCollecting importlib-metadata<2.0.0,>=1.6.0\n",
            "  Downloading importlib_metadata-1.7.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting pkginfo<2.0,>=1.4\n",
            "  Downloading pkginfo-1.8.3-py2.py3-none-any.whl (26 kB)\n",
            "Collecting keyring>=21.2.0\n",
            "  Downloading keyring-23.7.0-py3-none-any.whl (34 kB)\n",
            "Collecting requests-toolbelt<0.10.0,>=0.9.1\n",
            "  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54 kB 3.5 MB/s \n",
            "\u001b[?25hCollecting shellingham<2.0,>=1.1\n",
            "  Downloading shellingham-1.4.0-py2.py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: requests<3.0,>=2.18 in /usr/local/lib/python3.7/dist-packages (from poetry) (2.28.1)\n",
            "Requirement already satisfied: crashtest<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from poetry) (0.3.1)\n",
            "Requirement already satisfied: cachecontrol[filecache]<0.13.0,>=0.12.9 in /usr/local/lib/python3.7/dist-packages (from poetry) (0.12.11)\n",
            "Requirement already satisfied: html5lib<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from poetry) (1.0.1)\n",
            "Requirement already satisfied: clikit<0.7.0,>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from poetry) (0.6.2)\n",
            "Collecting poetry-core<1.1.0,>=1.0.7\n",
            "  Downloading poetry_core-1.0.8-py2.py3-none-any.whl (425 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 425 kB 63.4 MB/s \n",
            "\u001b[?25hCollecting packaging<21.0,>=20.4\n",
            "  Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40 kB 7.5 MB/s \n",
            "\u001b[?25hCollecting tomlkit<1.0.0,>=0.7.0\n",
            "  Downloading tomlkit-0.11.1-py3-none-any.whl (34 kB)\n",
            "Collecting cachy<0.4.0,>=0.3.0\n",
            "  Downloading cachy-0.3.0-py2.py3-none-any.whl (20 kB)\n",
            "Collecting cleo<0.9.0,>=0.8.1\n",
            "  Downloading cleo-0.8.1-py2.py3-none-any.whl (21 kB)\n",
            "Collecting virtualenv<21.0.0,>=20.0.26\n",
            "  Downloading virtualenv-20.16.2-py2.py3-none-any.whl (8.8 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8.8 MB 53.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pexpect<5.0.0,>=4.7.0 in /usr/local/lib/python3.7/dist-packages (from poetry) (4.8.0)\n",
            "Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from cachecontrol[filecache]<0.13.0,>=0.12.9->poetry) (1.0.4)\n",
            "Collecting lockfile>=0.9\n",
            "  Downloading lockfile-0.12.2-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: pylev<2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from clikit<0.7.0,>=0.6.2->poetry) (1.4.0)\n",
            "Requirement already satisfied: pastel<0.3.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from clikit<0.7.0,>=0.6.2->poetry) (0.2.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from html5lib<2.0,>=1.0->poetry) (0.5.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from html5lib<2.0,>=1.0->poetry) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<2.0.0,>=1.6.0->poetry) (3.8.1)\n",
            "Collecting jeepney>=0.4.2\n",
            "  Downloading jeepney-0.8.0-py3-none-any.whl (48 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48 kB 7.1 MB/s \n",
            "\u001b[?25hCollecting SecretStorage>=3.2\n",
            "  Downloading SecretStorage-3.3.2-py3-none-any.whl (15 kB)\n",
            "Collecting keyring>=21.2.0\n",
            "  Downloading keyring-23.6.0-py3-none-any.whl (34 kB)\n",
            "  Downloading keyring-23.5.1-py3-none-any.whl (33 kB)\n",
            "  Downloading keyring-23.5.0-py3-none-any.whl (33 kB)\n",
            "  Downloading keyring-23.4.1-py3-none-any.whl (33 kB)\n",
            "  Downloading keyring-23.4.0-py3-none-any.whl (33 kB)\n",
            "  Downloading keyring-23.3.0-py3-none-any.whl (33 kB)\n",
            "  Downloading keyring-23.2.1-py3-none-any.whl (33 kB)\n",
            "  Downloading keyring-23.2.0-py3-none-any.whl (33 kB)\n",
            "  Downloading keyring-23.1.0-py3-none-any.whl (32 kB)\n",
            "  Downloading keyring-23.0.1-py3-none-any.whl (33 kB)\n",
            "  Downloading keyring-23.0.0-py3-none-any.whl (32 kB)\n",
            "  Downloading keyring-22.4.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58 kB 8.1 MB/s \n",
            "\u001b[?25h  Downloading keyring-22.3.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58 kB 8.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging<21.0,>=20.4->poetry) (3.0.9)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect<5.0.0,>=4.7.0->poetry) (0.7.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.18->poetry) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.18->poetry) (2.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.18->poetry) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.18->poetry) (2022.6.15)\n",
            "Collecting cryptography>=2.0\n",
            "  Downloading cryptography-37.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.1 MB 58.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.0->SecretStorage>=3.2->keyring>=21.2.0->poetry) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.0->SecretStorage>=3.2->keyring>=21.2.0->poetry) (2.21)\n",
            "Requirement already satisfied: filelock<4,>=3.2 in /usr/local/lib/python3.7/dist-packages (from virtualenv<21.0.0,>=20.0.26->poetry) (3.7.1)\n",
            "Collecting platformdirs<3,>=2\n",
            "  Downloading platformdirs-2.5.2-py3-none-any.whl (14 kB)\n",
            "Collecting distlib<1,>=0.3.1\n",
            "  Downloading distlib-0.3.5-py2.py3-none-any.whl (466 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 466 kB 73.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: jeepney, cryptography, SecretStorage, platformdirs, lockfile, importlib-metadata, distlib, virtualenv, tomlkit, shellingham, requests-toolbelt, poetry-core, pkginfo, packaging, keyring, cleo, cachy, poetry\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.12.0\n",
            "    Uninstalling importlib-metadata-4.12.0:\n",
            "      Successfully uninstalled importlib-metadata-4.12.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 21.3\n",
            "    Uninstalling packaging-21.3:\n",
            "      Successfully uninstalled packaging-21.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "markdown 3.4.1 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 1.7.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed SecretStorage-3.3.2 cachy-0.3.0 cleo-0.8.1 cryptography-37.0.4 distlib-0.3.5 importlib-metadata-1.7.0 jeepney-0.8.0 keyring-22.3.0 lockfile-0.12.2 packaging-20.9 pkginfo-1.8.3 platformdirs-2.5.2 poetry-1.1.14 poetry-core-1.0.8 requests-toolbelt-0.9.1 shellingham-1.4.0 tomlkit-0.11.1 virtualenv-20.16.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "packaging"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating virtualenv \u001b[36mmmc-Gu1DbGS0-py3.7\u001b[0m in /root/.cache/pypoetry/virtualenvs\n",
            "Building \u001b[36mmmc\u001b[0m (\u001b[39;1m0.1.0\u001b[0m)\n",
            "  - Building \u001b[34msdist\u001b[0m\n",
            "  - Built \u001b[32mmmc-0.1.0.tar.gz\u001b[0m\n",
            "  - Building \u001b[34mwheel\u001b[0m\n",
            "  - Built \u001b[32mmmc-0.1.0-py3-none-any.whl\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing ./dist/mmc-0.1.0-py3-none-any.whl\n",
            "Collecting open-clip-torch@ git+https://github.com/mlfoundations/open_clip@main\n",
            "  Cloning https://github.com/mlfoundations/open_clip (to revision main) to /tmp/pip-install-28dpowrz/open-clip-torch_74aae7d4930746e99644be69e66fabb1\n",
            "  Running command git clone -q https://github.com/mlfoundations/open_clip /tmp/pip-install-28dpowrz/open-clip-torch_74aae7d4930746e99644be69e66fabb1\n",
            "Collecting clip@ git+https://github.com/openai/CLIP@main\n",
            "  Cloning https://github.com/openai/CLIP (to revision main) to /tmp/pip-install-28dpowrz/clip_92952c8e8dc54d23b3f03e2900eca332\n",
            "  Running command git clone -q https://github.com/openai/CLIP /tmp/pip-install-28dpowrz/clip_92952c8e8dc54d23b3f03e2900eca332\n",
            "Collecting kelip@ git+https://github.com/navervision/KELIP.git@master\n",
            "  Cloning https://github.com/navervision/KELIP.git (to revision master) to /tmp/pip-install-28dpowrz/kelip_80514d070aee44eaba7c1b484ff5e708\n",
            "  Running command git clone -q https://github.com/navervision/KELIP.git /tmp/pip-install-28dpowrz/kelip_80514d070aee44eaba7c1b484ff5e708\n",
            "Collecting declip@ git+https://github.com/pytti-tools/DeCLIP@installable\n",
            "  Cloning https://github.com/pytti-tools/DeCLIP (to revision installable) to /tmp/pip-install-28dpowrz/declip_5d060eea63634e5f8ff92f438cd5d59e\n",
            "  Running command git clone -q https://github.com/pytti-tools/DeCLIP /tmp/pip-install-28dpowrz/declip_5d060eea63634e5f8ff92f438cd5d59e\n",
            "  Running command git checkout -b installable --track origin/installable\n",
            "  Switched to a new branch 'installable'\n",
            "  Branch 'installable' set up to track remote branch 'installable' from 'origin'.\n",
            "Collecting kornia<0.7.0,>=0.6.4\n",
            "  Downloading kornia-0.6.6-py2.py3-none-any.whl (517 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 517 kB 15.0 MB/s \n",
            "\u001b[?25hCollecting napm<0.3.0,>=0.2.0\n",
            "  Downloading napm-0.2.2-py3-none-any.whl (6.1 kB)\n",
            "Requirement already satisfied: loguru<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from mmc==0.1.0) (0.6.0)\n",
            "Requirement already satisfied: Pillow<8.0.0,>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from mmc==0.1.0) (7.1.2)\n",
            "Collecting sentence-transformers<3.0.0,>=2.2.0\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85 kB 5.9 MB/s \n",
            "\u001b[?25hCollecting timm<0.6.0,>=0.5.4\n",
            "  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 431 kB 63.8 MB/s \n",
            "\u001b[?25hCollecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53 kB 2.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from clip@ git+https://github.com/openai/CLIP@main->mmc==0.1.0) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from clip@ git+https://github.com/openai/CLIP@main->mmc==0.1.0) (4.64.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from clip@ git+https://github.com/openai/CLIP@main->mmc==0.1.0) (1.12.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from clip@ git+https://github.com/openai/CLIP@main->mmc==0.1.0) (0.13.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from kelip@ git+https://github.com/navervision/KELIP.git@master->mmc==0.1.0) (1.21.6)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.21.0-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.7 MB 62.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from kornia<0.7.0,>=0.6.4->mmc==0.1.0) (20.9)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.27.1 in /usr/local/lib/python3.7/dist-packages (from napm<0.3.0,>=0.2.0->mmc==0.1.0) (2.28.1)\n",
            "Requirement already satisfied: gdown<5.0.0,>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from napm<0.3.0,>=0.2.0->mmc==0.1.0) (4.4.0)\n",
            "Requirement already satisfied: omegaconf<3.0.0,>=2.1.1 in /usr/local/lib/python3.7/dist-packages (from napm<0.3.0,>=0.2.0->mmc==0.1.0) (2.2.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown<5.0.0,>=4.4.0->napm<0.3.0,>=0.2.0->mmc==0.1.0) (4.6.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown<5.0.0,>=4.4.0->napm<0.3.0,>=0.2.0->mmc==0.1.0) (1.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown<5.0.0,>=4.4.0->napm<0.3.0,>=0.2.0->mmc==0.1.0) (3.7.1)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.7/dist-packages (from omegaconf<3.0.0,>=2.1.1->napm<0.3.0,>=0.2.0->mmc==0.1.0) (4.9.3)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from omegaconf<3.0.0,>=2.1.1->napm<0.3.0,>=0.2.0->mmc==0.1.0) (6.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.27.1->napm<0.3.0,>=0.2.0->mmc==0.1.0) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.27.1->napm<0.3.0,>=0.2.0->mmc==0.1.0) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.27.1->napm<0.3.0,>=0.2.0->mmc==0.1.0) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.27.1->napm<0.3.0,>=0.2.0->mmc==0.1.0) (2022.6.15)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers<3.0.0,>=2.2.0->mmc==0.1.0) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers<3.0.0,>=2.2.0->mmc==0.1.0) (1.7.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers<3.0.0,>=2.2.0->mmc==0.1.0) (3.7)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.2 MB 59.3 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub>=0.4.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101 kB 11.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers<3.0.0,>=2.2.0->mmc==0.1.0) (1.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers<3.0.0,>=2.2.0->mmc==0.1.0) (4.1.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->kornia<0.7.0,>=0.6.4->mmc==0.1.0) (3.0.9)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.6 MB 53.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->clip@ git+https://github.com/openai/CLIP@main->mmc==0.1.0) (0.2.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence-transformers<3.0.0,>=2.2.0->mmc==0.1.0) (3.8.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers<3.0.0,>=2.2.0->mmc==0.1.0) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers<3.0.0,>=2.2.0->mmc==0.1.0) (7.1.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.27.1->napm<0.3.0,>=0.2.0->mmc==0.1.0) (1.7.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers<3.0.0,>=2.2.0->mmc==0.1.0) (3.1.0)\n",
            "Building wheels for collected packages: clip, declip, kelip, open-clip-torch, sentence-transformers\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369409 sha256=863aac0a188d17c78846189df3ce976c12b61751238970d55a7691e0741f8481\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-unohly2h/wheels/e7/d4/8d/e93c3370dafc4c1e08e5201a98ab326b8a4735b753841ff187\n",
            "  Building wheel for declip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for declip: filename=DeCLIP-3.0.0b0-py3-none-any.whl size=156144 sha256=93ed93a23ac3fe6bc10194e2972b04b9f6e3aba730bb1b1ff0767fa115bddf3f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-unohly2h/wheels/c9/d0/36/5b9c8c6bd747527e47f57cd332471e2e85a0de61133654f20f\n",
            "  Building wheel for kelip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kelip: filename=kelip-0.1.0-py3-none-any.whl size=14122 sha256=8b03d30e5bb825f0f3d4f639664791f292a51a4a71a4e70836702c03a5861923\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-unohly2h/wheels/f8/c1/74/6867b3df0cc4328380c02d43faae34c1080e2d098e546faa9e\n",
            "  Building wheel for open-clip-torch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for open-clip-torch: filename=open_clip_torch-1.3.0-py3-none-any.whl size=1398735 sha256=b9d7d4e81dcd54e7f29182770b4e6ef98134af8a75a336890087beca2b312f6c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-unohly2h/wheels/ed/0d/00/5c2bef77ee96e43ac9c6606437ed80a399f4b686ae3e0e763f\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=1c3ac91e78f523bf466e508be7e6cea3db57a7fcb20a3f3e9f0607241559e03f\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/06/fb/d59c1e5bd1dac7f6cf61ec0036cc3a10ab8fecaa6b2c3d3ee9\n",
            "Successfully built clip declip kelip open-clip-torch sentence-transformers\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers, sentencepiece, ftfy, timm, sentence-transformers, open-clip-torch, napm, kornia, kelip, declip, clip, mmc\n",
            "  Attempting uninstall: timm\n",
            "    Found existing installation: timm 0.6.7\n",
            "    Uninstalling timm-0.6.7:\n",
            "      Successfully uninstalled timm-0.6.7\n",
            "  Attempting uninstall: napm\n",
            "    Found existing installation: napm 1.0.1\n",
            "    Uninstalling napm-1.0.1:\n",
            "      Successfully uninstalled napm-1.0.1\n",
            "Successfully installed clip-1.0 declip-3.0.0b0 ftfy-6.1.1 huggingface-hub-0.8.1 kelip-0.1.0 kornia-0.6.6 mmc-0.1.0 napm-0.2.2 open-clip-torch-1.3.0 sentence-transformers-2.2.2 sentencepiece-0.1.96 timm-0.5.4 tokenizers-0.12.1 transformers-4.21.0\n",
            "\u001b[32m2022-07-27 23:33:54.678\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mnapm.config\u001b[0m:\u001b[36mconfig_path\u001b[0m:\u001b[36m28\u001b[0m - \u001b[34m\u001b[1m/root/.cache/napm/config.yaml\u001b[0m\n",
            "\u001b[32m2022-07-27 23:33:54.682\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mnapm.config\u001b[0m:\u001b[36mconfig_path\u001b[0m:\u001b[36m28\u001b[0m - \u001b[34m\u001b[1m/root/.cache/napm/config.yaml\u001b[0m\n",
            "\u001b[32m2022-07-27 23:33:54.683\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mnapm_pi_katcloob\u001b[0m:\u001b[36m18\u001b[0m - \u001b[34m\u001b[1musing napm to \"install\" katCLOOB\u001b[0m\n",
            "Cloning into '/root/.cache/napm/cloob'...\n",
            "remote: Enumerating objects: 35, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 35 (delta 13), reused 31 (delta 9), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (35/35), done.\n",
            "\u001b[32m2022-07-27 23:33:55.056\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mnapm.config\u001b[0m:\u001b[36mconfig_path\u001b[0m:\u001b[36m28\u001b[0m - \u001b[34m\u001b[1m/root/.cache/napm/config.yaml\u001b[0m\n",
            "\u001b[32m2022-07-27 23:33:55.058\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mnapm.config\u001b[0m:\u001b[36mconfig_path\u001b[0m:\u001b[36m28\u001b[0m - \u001b[34m\u001b[1m/root/.cache/napm/config.yaml\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "# just use the machinery in pytti for now\n",
        "# super bloated installation relative to what we need\n",
        "\n",
        "\n",
        "# { display-mode: 'form' }\n",
        "\n",
        "\n",
        "## 1. Install stuff\n",
        "\n",
        "try: \n",
        "    import pytti\n",
        "except ImportError:\n",
        "    !pip install kornia pytorch-lightning transformers\n",
        "    !pip install jupyter loguru einops PyGLM ftfy regex tqdm hydra-core exrex\n",
        "    !pip install seaborn adjustText bunch matplotlib-label-lines\n",
        "    !pip install --upgrade gdown\n",
        "\n",
        "    !pip install --upgrade git+https://github.com/pytti-tools/AdaBins.git\n",
        "    !pip install --upgrade git+https://github.com/pytti-tools/GMA.git\n",
        "    !pip install --upgrade git+https://github.com/pytti-tools/taming-transformers.git\n",
        "    #!pip install --upgrade git+https://github.com/openai/CLIP.git\n",
        "    !pip install --upgrade git+https://github.com/pytti-tools/pytti-core.git\n"
      ],
      "metadata": {
        "id": "omr1twEbWG5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6Ri2kT3N3Gc"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import io\n",
        "import os, time, glob\n",
        "import pickle\n",
        "import shutil\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import requests\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "import clip # should get installed with mmc?\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
        "from IPython.display import display\n",
        "from einops import rearrange\n",
        "from google.colab import files\n",
        "\n",
        "# these two are from stylegan-xl\n",
        "import dnnlib\n",
        "import legacy\n",
        "\n",
        "import PIL\n",
        "\n",
        "from pytti.LossAug.OpticalFlowLossClass import (\n",
        "    init_GMA,\n",
        "    OpticalFlowLoss,\n",
        ")\n",
        "\n",
        "from pytti.Perceptor.cutouts import augs as cutouts_augs\n",
        "import mmc.loaders"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device = torch.device('cuda:0')\n",
        "print('Using device:', device, file=sys.stderr)\n",
        "\n",
        "# Functions (many must be trimmed too)\n",
        "\n",
        "def fetch(url_or_path):\n",
        "    if str(url_or_path).startswith('http://') or str(url_or_path).startswith('https://'):\n",
        "        r = requests.get(url_or_path)\n",
        "        r.raise_for_status()\n",
        "        fd = io.BytesIO()\n",
        "        fd.write(r.content)\n",
        "        fd.seek(0)\n",
        "        return fd\n",
        "    return open(url_or_path, 'rb')\n",
        "\n",
        "def fetch_model(url_or_path):\n",
        "    !wget -c '{url_or_path}'\n",
        "\n",
        "def slugify(value, allow_unicode=False):\n",
        "    \"\"\"\n",
        "    Taken from https://github.com/django/django/blob/master/django/utils/text.py\n",
        "    Convert to ASCII if 'allow_unicode' is False. Convert spaces or repeated\n",
        "    dashes to single dashes. Remove characters that aren't alphanumerics,\n",
        "    underscores, or hyphens. Convert to lowercase. Also strip leading and\n",
        "    trailing whitespace, dashes, and underscores.\n",
        "    \"\"\"\n",
        "    value = str(value)\n",
        "    if allow_unicode:\n",
        "        value = unicodedata.normalize('NFKC', value)\n",
        "    else:\n",
        "        value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode('ascii')\n",
        "    value = re.sub(r'[^\\w\\s-]', '', value.lower())\n",
        "    return re.sub(r'[-\\s]+', '-', value).strip('-_')\n",
        "\n",
        "def norm1(prompt):\n",
        "    \"Normalize to the unit sphere.\"\n",
        "    return prompt / prompt.square().sum(dim=-1,keepdim=True).sqrt()\n",
        "\n",
        "def spherical_dist_loss(x, y):\n",
        "    x = F.normalize(x, dim=-1)\n",
        "    y = F.normalize(y, dim=-1)\n",
        "    return (x - y).norm(dim=-1).div(2).arcsin().pow(2).mul(2)\n",
        "\n",
        "def prompts_dist_loss(x, targets, loss):\n",
        "    if len(targets) == 1: # Keeps consitent results vs previous method for single objective guidance \n",
        "      return loss(x, targets[0])\n",
        "    distances = [loss(x, target) for target in targets]\n",
        "    return torch.stack(distances, dim=-1).sum(dim=-1)  \n",
        "\n",
        "class MakeCutouts(torch.nn.Module):\n",
        "    def __init__(self, cut_size, cutn, cut_pow=1.):\n",
        "        super().__init__()\n",
        "        self.cut_size = cut_size\n",
        "        self.cutn = cutn\n",
        "        self.cut_pow = cut_pow\n",
        "        self.augs = cutouts_augs.pytti_classic()\n",
        "\n",
        "    def forward(self, input):\n",
        "        sideY, sideX = input.shape[2:4]\n",
        "        max_size = min(sideX, sideY)\n",
        "        min_size = min(sideX, sideY, self.cut_size)\n",
        "        cutouts = []\n",
        "        for _ in range(self.cutn):\n",
        "            size = int(torch.rand([])**self.cut_pow * (max_size - min_size) + min_size)\n",
        "            offsetx = torch.randint(0, sideX - size + 1, ())\n",
        "            offsety = torch.randint(0, sideY - size + 1, ())\n",
        "            cutout = input[:, :, offsety:offsety + size, offsetx:offsetx + size]\n",
        "            cutouts.append(F.adaptive_avg_pool2d(cutout, self.cut_size))\n",
        "        return self.augs(torch.cat(cutouts))\n",
        "\n",
        "# to do: move this. or reparameterize it. or something.\n",
        "n_cutouts = 32 # @param {type:'integer'}\n",
        "cut_power = 0.5 # @param {type:'number'}\n",
        "make_cutouts = MakeCutouts(224, n_cutouts, cut_power)\n",
        "\n",
        "def embed_image(image):\n",
        "  n = image.shape[0]\n",
        "  cutouts = make_cutouts(image)\n",
        "  embeds = clip_model.embed_cutout(cutouts)\n",
        "  embeds = rearrange(embeds, '(cc n) c -> cc n c', n=n)\n",
        "  return embeds\n",
        "\n",
        "def embed_url(url):\n",
        "  image = Image.open(fetch(url)).convert('RGB')\n",
        "  return embed_image(TF.to_tensor(image).to(device).unsqueeze(0)).mean(0).squeeze(0)\n",
        "\n",
        "class CLIP(object):\n",
        "  def __init__(self):\n",
        "    clip_model = \"ViT-B/16\"\n",
        "    self.model, _ = clip.load(clip_model)\n",
        "    self.model = self.model.requires_grad_(False)\n",
        "    self.normalize = transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073],\n",
        "                                          std=[0.26862954, 0.26130258, 0.27577711])\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def embed_text(self, prompt):\n",
        "      \"Normalized clip text embedding.\"\n",
        "      return norm1(self.model.encode_text(clip.tokenize(prompt).to(device)).float())\n",
        "\n",
        "  def embed_cutout(self, image):\n",
        "      \"Normalized clip image embedding.\"\n",
        "      return norm1(self.model.encode_image(self.normalize(image)))\n",
        "  \n",
        "clip_model = CLIP()\n",
        "init_GMA()"
      ],
      "metadata": {
        "id": "AKcpB5w1812Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #**Optional:** Save outputs to Google Drive ðŸ’¾\n",
        "# @markdown Run this cell if you want to store the results inside Google Drive.\n",
        "\n",
        "# @markdown Copying the generated images to drive is faster to work with.\n",
        "\n",
        "# @markdown **Important**: you must have a folder named *samples* inside your drive, otherwise this may not work.\n",
        "\n",
        "\n",
        "mount_drive = False # @param {type:'boolean'}\n",
        "if mount_drive:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "JhTuiOf4mUuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "guZeRGM6OmaU"
      },
      "outputs": [],
      "source": [
        "#@markdown #**Model selection** ðŸŽ­\n",
        "\n",
        "Model = 'Imagenet-1024' #@param [\"Imagenet-1024\", \"Imagenet-512\", \"Imagenet-256\", \"Imagenet-128\", \"Pokemon\", \"FFHQ\"]\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "network_url = {\n",
        "    \"Imagenet-1024\": \"https://s3.eu-central-1.amazonaws.com/avg-projects/stylegan_xl/models/imagenet1024.pkl\",\n",
        "    \"Imagenet-512\": \"https://s3.eu-central-1.amazonaws.com/avg-projects/stylegan_xl/models/imagenet512.pkl\",\n",
        "    \"Imagenet-256\": \"https://s3.eu-central-1.amazonaws.com/avg-projects/stylegan_xl/models/imagenet256.pkl\",\n",
        "    \"Imagenet-128\": \"https://s3.eu-central-1.amazonaws.com/avg-projects/stylegan_xl/models/imagenet128.pkl\",\n",
        "    \"Pokemon-1024\": \"https://s3.eu-central-1.amazonaws.com/avg-projects/stylegan_xl/models/pokemon1024.pkl\",\n",
        "    \"Pokemon-512\": \"https://s3.eu-central-1.amazonaws.com/avg-projects/stylegan_xl/models/pokemon512.pkl\",\n",
        "    \"Pokemon-256\": \"https://s3.eu-central-1.amazonaws.com/avg-projects/stylegan_xl/models/pokemon256.pkl\",\n",
        "    \"FFHQ-256\": \"https://s3.eu-central-1.amazonaws.com/avg-projects/stylegan_xl/models/ffhq256.pkl\"\n",
        "}\n",
        "\n",
        "network_name = network_url[Model].split(\"/\")[-1]\n",
        "fetch_model(network_url[Model])\n",
        "\n",
        "with dnnlib.util.open_url(network_name) as f:\n",
        "    G = legacy.load_network_pkl(f)['G_ema'].to(device) # type: ignore\n",
        "\n",
        "\n",
        "zs = torch.randn([10000, G.mapping.z_dim], device=device)\n",
        "cs = torch.zeros([10000, G.mapping.c_dim], device=device)\n",
        "for i in range(cs.shape[0]):\n",
        "  cs[i,i//10]=1\n",
        "w_stds = G.mapping(zs, cs)\n",
        "w_stds = w_stds.reshape(10, 1000, G.num_ws, -1)\n",
        "w_stds=w_stds.std(0).mean(0)[0]\n",
        "w_all_classes_avg = G.mapping.w_avg.mean(0)\n",
        "\n",
        "aggressive_stabilization = False  # @param {type:'boolean'}\n",
        "\n",
        "dejiggle_weight=1000 # @param {type:'number'}\n",
        "\n",
        "ema_decay = 0.5 # @param {type:'number'}\n",
        "\n",
        "if aggressive_stabilization:\n",
        "  dejiggle_weight = 0\n",
        "\n",
        "#####################################################\n",
        "# stabilization snippet via @PDillis\n",
        "# https://twitter.com/PDillis/status/1551673599878209544\n",
        "if hasattr(G.synthesis, 'input') and aggressive_stabilization:\n",
        "    if G.c_dim == 0:\n",
        "        shift = (G\n",
        "            .synthesis\n",
        "            .input\n",
        "            .affine(G.mapping.w_avg.unsqueeze(0))\n",
        "            .squeeze(0)\n",
        "        )\n",
        "    else:\n",
        "        shift = (G\n",
        "            .synthesis\n",
        "            .input\n",
        "            .affine(G.mapping.w_avg)\n",
        "            .mean(0)\n",
        "        )\n",
        "    G.synthesis.input.affine.bias.data.add_(shift)\n",
        "    G.synthesis.input.affine.weight.data.zero_()\n",
        "#####################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tAknegrdPM-d"
      },
      "outputs": [],
      "source": [
        "#@markdown #**Run the model** ðŸš€\n",
        "#@markdown `texts`: Enter here a prompt to guide the image generation. You can enter more than one prompt separated with\n",
        "#@markdown `|`, which will cause the guidance to focus on the different prompts at the same time, allowing to mix and play\n",
        "#@markdown with the generation process.\n",
        "\n",
        "#@markdown `steps`: Number of optimization steps. The more steps, the longer it will try to generate an image relevant to the prompt.\n",
        "\n",
        "#@markdown `seed`: Determines the randomness seed. Using the same seed and prompt should give you similar results at every run.\n",
        "#@markdown Use `-1` for a random seed.\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "import einops as ei\n",
        "\n",
        "\n",
        "#texts = \"the loom of the gods\" #@param {type:\"string\"}\n",
        "texts = \"steampunk laser dance party | mechanical gears | chaotic clockwork mechanisms | colorful interference \" #@param {type:\"string\"}\n",
        "steps_per_frame =  20#@param {type:\"number\"}\n",
        "\n",
        "frames_to_generate =  60#@param {type:\"number\"}\n",
        "steps = frames_to_generate * steps_per_frame\n",
        "warmup_steps = 50\n",
        "seed = 12345 #@param {type:\"number\"}\n",
        "learning_rate = 0.01 #@param {type:\"number\"}\n",
        "reset_lr_each_frame = True # @param {type:\"boolean\"}\n",
        "\n",
        "save_every = steps_per_frame\n",
        "\n",
        "if seed == -1:\n",
        "    seed = np.random.randint(0,9e9)\n",
        "    print(f\"Your random seed is: {seed}\")\n",
        "\n",
        "texts = [frase.strip() for frase in texts.split(\"|\") if frase]\n",
        "\n",
        "targets = [clip_model.embed_text(text) for text in texts]\n",
        "\n",
        "\n",
        "tf = Compose([\n",
        "  Resize(224),\n",
        "  lambda x: torch.clamp((x+1)/2,min=0,max=1),\n",
        "])\n",
        "\n",
        "initial_batch=4 #actually that will be multiplied by initial_image_steps\n",
        "initial_image_steps=warmup_steps\n",
        "'''\n",
        "c = torch.zeros((1000)) #just to pick a closer initial image\n",
        "c[initial_class]=1\n",
        "c = c.repeat(initial_batch, 1)\n",
        "c=c.to(device)\n",
        "'''\n",
        "def run(timestring):\n",
        "  flow=None\n",
        "  torch.manual_seed(seed)\n",
        "  with torch.no_grad():\n",
        "    qs = []\n",
        "    losses = []\n",
        "    for _ in range(initial_image_steps):\n",
        "      a = torch.randn([initial_batch, 512], device=device)*0.6 + w_all_classes_avg*0.4\n",
        "      q = ((a-w_all_classes_avg)/w_stds)\n",
        "      images = G.synthesis((q * w_stds + w_all_classes_avg).unsqueeze(1).repeat([1, G.num_ws, 1]))\n",
        "      embeds = embed_image(images.add(1).div(2))\n",
        "      loss = prompts_dist_loss(embeds, targets, spherical_dist_loss).mean(0)\n",
        "      i = torch.argmin(loss)\n",
        "      qs.append(q[i])\n",
        "      losses.append(loss[i])\n",
        "    qs = torch.stack(qs)\n",
        "    losses = torch.stack(losses)\n",
        "    i = torch.argmin(losses)\n",
        "    q = qs[i].unsqueeze(0).repeat([G.num_ws, 1]).requires_grad_()\n",
        "    # print(q)\n",
        "    # q = qs[i].unsqueeze(0).repeat([G.num_ws, 1])\n",
        "    # q = torch.tensor(q, requires_grad=True)\n",
        "    # print(q)\n",
        "\n",
        "  im_prev=None\n",
        "  # Sampling loop\n",
        "  q_ema = q\n",
        "  # print(q.shape)\n",
        "  # opt = ESGD([q], lr=0.03, betas=(0.9, 0.999), nu=0.9)\n",
        "  opt = torch.optim.AdamW([q], lr=learning_rate, betas=(0., 0.999), weight_decay=0.025)\n",
        "  loop = tqdm(range(steps))\n",
        "  j = 0\n",
        "  for i in loop:\n",
        "    opt.zero_grad()\n",
        "\n",
        "    w = q * w_stds\n",
        "    image = G.synthesis((q * w_stds + w_all_classes_avg)[None], noise_mode='const')\n",
        "    embed = embed_image(image.add(1).div(2))\n",
        "    loss = prompts_dist_loss(embed, targets, spherical_dist_loss).mean()\n",
        "\n",
        "    ##############\n",
        "    # de-jiggle loss\n",
        "    if (im_prev is not None) and (dejiggle_weight != 0):\n",
        "        flow = OpticalFlowLoss.get_flow(im_prev, image)\n",
        "        net_flow = flow.mean()\n",
        "        loss += dejiggle_weight * net_flow\n",
        "\n",
        "    ##############\n",
        "    # loss.backward(create_graph=opt.should_create_graph())\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    loop.set_postfix(loss=loss.item(), q_magnitude=q.std().item())\n",
        "\n",
        "    if i % save_every == 0:\n",
        "      q_ema = q_ema * (1-ema_decay) + q * ema_decay\n",
        "      image = G.synthesis((q_ema * w_stds + w_all_classes_avg)[None],\n",
        "                          noise_mode='const',                        \n",
        "                          )\n",
        "      if reset_lr_each_frame:\n",
        "          opt = torch.optim.AdamW([q], lr=learning_rate, betas=(0., 0.999), weight_decay=0.025)\n",
        "\n",
        "      with torch.no_grad():\n",
        "        im_prev = image.clone().detach()\n",
        "      if i % 10 == 0 or i == (steps - 1):\n",
        "        display(TF.to_pil_image(tf(image)[0]))\n",
        "        print(f\"Image {j}/{frames_to_generate}, steps {i}/{steps} | Current loss: {loss}\")\n",
        "        #####################\n",
        "        #if flow is not None:\n",
        "        #  im_t_flow_fwd = ei.rearrange(flow, 'b c h w -> b h w c')\n",
        "        #  arr_flow_fwd = flow_to_image(im_t_flow_fwd.squeeze().detach().clone().cpu().numpy())\n",
        "        #  display(flow2pil(arr_flow_fwd))\n",
        "\n",
        "      pil_image = TF.to_pil_image(image[0].add(1).div(2).clamp(0,1))\n",
        "      os.makedirs(f'samples/{timestring}', exist_ok=True)\n",
        "      pil_image.save(f'samples/{timestring}/{j:04}.jpg')\n",
        "      j+=1\n",
        "\n",
        "try:\n",
        "  timestring = time.strftime('%Y%m%d%H%M%S')\n",
        "  run(timestring)\n",
        "except KeyboardInterrupt:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #**Generate video** ðŸŽ¥\n",
        "\n",
        "#@markdown You can edit frame rate and stuff by double-clicking this tab.\n",
        "\n",
        "frames = os.listdir(f\"samples/{timestring}\")\n",
        "frames = len(list(filter(lambda filename: filename.endswith(\".jpg\"), frames))) #Get number of jpg generated\n",
        "\n",
        "init_frame = 1 #This is the frame where the video will start\n",
        "last_frame = frames #You can change i to the number of the last frame you want to generate. It will raise an error if that number of frames does not exist.\n",
        "\n",
        "min_fps = 10\n",
        "max_fps = 60\n",
        "\n",
        "total_frames = last_frame-init_frame\n",
        "\n",
        "#Desired video time in seconds\n",
        "video_length =  5#@param {type:\"number\"}\n",
        "#Video filename\n",
        "video_name = \"caffeinated_saveevery10_lr0.01_lr-reset_antijitter1000\" #@param {type:\"string\"}\n",
        "video_name = slugify(video_name)\n",
        "\n",
        "if not video_name:\n",
        "  video_name = \"video\"\n",
        "# frames = []\n",
        "# tqdm.write('Generating video...')\n",
        "# for i in range(init_frame,last_frame): #\n",
        "#     filename = f\"samples/{timestring}/{i:04}.jpg\"\n",
        "#     frames.append(Image.open(filename))\n",
        "\n",
        "fps = np.clip(total_frames/video_length,min_fps,max_fps)\n",
        "\n",
        "print(\"Generating video...\")\n",
        "!ffmpeg -r {fps} -i samples/{timestring}/%04d.jpg -c:v libx264 -vf fps={fps} -pix_fmt yuv420p samples/{video_name}.mp4 -frames:v {total_frames}\n",
        "\n",
        "# from subprocess import Popen, PIPE\n",
        "# p = Popen(['ffmpeg', '-y', '-f', 'image2pipe', '-vcodec', 'png', '-r', str(fps), '-i', '-', '-vcodec', 'libx264', '-r', str(fps), '-pix_fmt', 'yuv420p', '-crf', '17', '-preset', 'veryslow', f'samples/{video_name}.mp4'], stdin=PIPE)\n",
        "# for im in tqdm(frames):\n",
        "#     im.save(p.stdin, 'PNG')\n",
        "# p.stdin.close()\n",
        "\n",
        "print(\"The video is ready\")"
      ],
      "metadata": {
        "id": "XhD937BdKRO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #**Download video** ðŸ“€\n",
        "#@markdown If you're activated the download to GDrive option, the video will be save there. Don't worry about overwritting issues for colliding filenames, an id will be added to them to avoid this.\n",
        "\n",
        "#Video filename\n",
        "#to_download_video_name = \"caffeinated_saveevery10_lr0.01_lr-reset\" #@param {type:\"string\"}\n",
        "#to_download_video_name = slugify(to_download_video_name)\n",
        "\n",
        "#if not to_download_video_name:\n",
        "to_download_video_name = video_name\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "if os.path.isdir('drive/MyDrive/samples'):\n",
        "  filelist = glob.glob(f'drive/MyDrive/samples/{to_download_video_name}*.mp4')\n",
        "  video_count = len(filelist)\n",
        "  if video_count:\n",
        "    final_video_name = f\"{to_download_video_name}{video_count}\"\n",
        "  else:\n",
        "    final_video_name = to_download_video_name\n",
        "  shutil.copyfile(f'samples/{video_name}.mp4', f'drive/MyDrive/samples/{final_video_name}.mp4')\n",
        "else:\n",
        "  files.download(f\"samples/{to_download_video_name}.mp4\")"
      ],
      "metadata": {
        "id": "2-I0zmhomm_q"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "StyleganXL+CLIP",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}